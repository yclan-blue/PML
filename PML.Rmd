Practical Machine Learning
========================================
by YU-CHING LAN  
github repo with RMarkdown source code:
https://github.com/yclan-blue/PML

To analysis the providing data for definding what activity an individual would perform, I use caret and randomForest for generating answers for each of the 20 test data cases provided here. 
## Loading and preprocessing the data
```{r}
setwd("~/Dropbox/2015BLUE-myself/mycoursera/ML")

library(knitr)
library(ggplot2)
library(lattice)
library(Hmisc)
library(caret)
library(randomForest)
library(foreach)
library(doParallel)
set.seed(2048)
options(warn=-1)
```

Here I loaded those two assignment data and replace the #DIV/0! value to NA. Then, I made all columns 8 become numeric.

```{r}
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!") )
evaluation_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!") )

for(i in c(8:ncol(training_data)-1)) {training_data[,i] = as.numeric(as.character(training_data[,i]))}
for(i in c(8:ncol(evaluation_data)-1)) {evaluation_data[,i] = as.numeric(as.character(evaluation_data[,i]))}
```

I set that only included the columns with complete information and also remove user name, timestamps and windows.  

```{r}
feature_set <- colnames(training_data[colSums(is.na(training_data)) == 0])[-(1:7)]
model_data <- training_data[feature_set]
feature_set
```

The model dataset was build up.
```{r}
index <- createDataPartition(y=model_data$classe, p=0.75, list=FALSE )
training <- model_data[index,]
testing <- model_data[-index,]
```

Here I made 5 random forests with 150 trees each. The parallel processing was use to build up the model. 

```{r}
registerDoParallel()
x <- training[-ncol(training)]
y <- training$classe

rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree) 
}
```

The error reports provided for training and test data.
```{r}
predictions1 <- predict(rf, newdata=training)
confusionMatrix(predictions1,training$classe)


predictions2 <- predict(rf, newdata=testing)
confusionMatrix(predictions2,testing$classe)
```

Conclusions

The confusion matrix and statistics show this model accurating. The test data was around 99% 
accurate and had expected nearly all cases would be correct. 

Test Data Submission

```{r}
pml_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}


x <- evaluation_data
x <- x[feature_set[feature_set!='classe']]
answers <- predict(rf, newdata=x)

answers

pml_files
```